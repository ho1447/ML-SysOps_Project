{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3810d717-0ce7-43e3-934e-773ec5a34d63",
   "metadata": {},
   "source": [
    "##  Lifecycle - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3707ed-e60d-44d4-af2f-3003ba05f42a",
   "metadata": {},
   "source": [
    "### Run a Training and Evaluation Job\n",
    "\n",
    "In this step, we will manually trigger a model training and evaluation process. This trigger might be required for reasons such as model updates or changes in production data.\n",
    "\n",
    "Through the previous workflow, we created an **Argo Workflow template** named `train-model.yaml`, which handles both training and evaluating the model.\n",
    "\n",
    "Let’s break down the key steps involved in this process:\n",
    "\n",
    "1. **Template Parameters**:\n",
    "   The template accepts three Public IP addresses as parameters:\n",
    "\n",
    "   * **train-ip**: The IP address for the Training Endpoint, responsible for triggering the model's training process and logging artifacts in **MLFlow**.\n",
    "   * **eval-ip**: The IP address for the Model Evaluation Endpoint, responsible for evaluating the model and registering it in **MLFlow** under a specific name.\n",
    "   * **mlflow-ip**: The IP address where MLFlow is accessible. This will be important for interacting with MLFlow during the training and evaluation process.\n",
    "\n",
    "2. **Training the Model**:\n",
    "   The training endpoint is triggered via an API call. The following code initiates the training process and logs the model artifacts:\n",
    "\n",
    "   ```bash\n",
    "   RESPONSE=$(curl -f -s -X POST \"http://{{inputs.parameters.train-ip}}:9090/train?model_name=resnet50&data_source=train\")\n",
    "   CURL_EXIT_CODE=$?\n",
    "   echo \"[INFO] Training endpoint response was: $RESPONSE\" >&2\n",
    "   if [ $CURL_EXIT_CODE -ne 0 ]; then\n",
    "     echo \"[ERROR] curl failed with code $CURL_EXIT_CODE\" >&2\n",
    "     exit $CURL_EXIT_CODE\n",
    "   fi\n",
    "   ```\n",
    "\n",
    "   Note that training can take a significant amount of time. The endpoint returns a **RUN\\_ID**, which is logged in **MLFlow**. Due to the training duration, HTTP endpoints have a timeout, but the **RUN\\_ID** is returned immediately to track the progress.\n",
    "\n",
    "3. **Polling for Training Completion**:\n",
    "   Since model training can take time, we continually poll the MLFlow API using the `RUN_ID` to track the status of the training job. The following code checks the training status:\n",
    "\n",
    "   ```bash\n",
    "   RUN_ID=$(echo \"$RESPONSE\" | jq -r '.run_id')\n",
    "   if [ -z \"$RUN_ID\" ]; then\n",
    "     echo \"[ERROR] run_id not found in response\" >&2\n",
    "     exit 1\n",
    "   fi\n",
    "   echo \"[INFO] MLflow run ID: $RUN_ID\" >&2\n",
    "\n",
    "   TERMINAL=\"FINISHED|FAILED|KILLED\"\n",
    "   while true; do\n",
    "     STATUS=$(curl -s \"http://{{inputs.parameters.mlflow-ip}}:8000/api/2.0/mlflow/runs/get?run_id=${RUN_ID}\" | jq -r '.run.info.status')\n",
    "     echo \"[INFO] Run ${RUN_ID} status: ${STATUS}\" >&2\n",
    "     case \"$STATUS\" in\n",
    "       FINISHED|FAILED|KILLED)\n",
    "         echo \"[INFO] Terminal state reached: $STATUS\" >&2\n",
    "         break\n",
    "         ;;\n",
    "     esac\n",
    "     sleep 10\n",
    "   done\n",
    "   ```\n",
    "\n",
    "4. **Model Evaluation and Registration**:\n",
    "   After training, the model must be evaluated. We trigger the **Model Evaluation Endpoint** to evaluate the model and register it in **MLFlow**. The version of the registered model is extracted and logged:\n",
    "\n",
    "   ```bash\n",
    "   EVAL_RESPONSE=$(curl -f -s -X GET \"http://{{inputs.parameters.eval-ip}}:8080/get-version?run_id=${RUN_ID}\")\n",
    "   CURL_EXIT_CODE=$?\n",
    "   echo \"[INFO] Evaluation endpoint response was: $EVAL_RESPONSE\" >&2\n",
    "   if [ $CURL_EXIT_CODE -ne 0 ]; then\n",
    "     echo \"[ERROR] curl failed with code $CURL_EXIT_CODE\" >&2\n",
    "     exit $CURL_EXIT_CODE\n",
    "   fi\n",
    "\n",
    "   VERSION=$(echo \"$EVAL_RESPONSE\" | jq -r '.new_model_version // empty')\n",
    "   if [ -z \"$VERSION\" ]; then\n",
    "     echo \"[WARN] 'new_model_version' not found in response.\" >&2\n",
    "     exit 1\n",
    "   fi\n",
    "   echo -n \"$VERSION\"\n",
    "   ```\n",
    "\n",
    "5. **Triggering the Workflow**:\n",
    "   To trigger the workflow, navigate to **Argo Workflows** > **Workflow Templates** > **Submit**, then provide the necessary IPs for **train-ip**, **eval-ip**, and **mlflow-ip**, and hit **Submit**.\n",
    "\n",
    "6. **Container Build**:\n",
    "   Once the model is registered, we trigger a **container build** automatically upon receiving the new model version from the training job. After the build completes, the latest model will be accessible via the endpoint:\n",
    "\n",
    "   ```bash\n",
    "   http://A.B.C.D:8081\n",
    "   ```\n",
    "\n",
    "This flow ensures that the latest model is trained, evaluated, and registered. The **FastAPI** wrapper for this model will then replace the existing model (`bird.pth`) with the newly trained one, making it available to users.\n",
    "\n",
    "Next, we’ll explore how this flow integrates into the system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdeb4fe-1ba4-4cc1-94a4-590a38ca13b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
